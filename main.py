import streamlit as st
import pandas as pd
import google.generativeai as genai
import time

# --- CONFIGURACI√ìN ---
PAGE_TITLE = "Lucho | Asesor Comercial"
PAGE_ICON = "üèóÔ∏è"
# USAMOS EL NOMBRE T√âCNICO CORRECTO DEL MODELO M√ÅS POTENTE ACTUAL
MODEL_ID = "gemini-1.5-pro" 
SHEET_URL = "https://docs.google.com/spreadsheets/d/e/2PACX-1vTgHzHMiNP9jH7vBAkpYiIVCzUaFbNKLC8_R9ZpwIbgMc7suQMR7yActsCdkww1VxtgBHcXOv4EGvXj/pub?gid=1937732333&single=true&output=csv"

st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON, layout="centered")

def configure_interface():
    st.title("üèóÔ∏è Habl√° con Lucho")
    st.markdown("**Atenci√≥n Comercial | Pedro Bravin**")

def get_data():
    try:
        df = pd.read_csv(SHEET_URL, encoding='utf-8', on_bad_lines='skip')
        return df.to_string(index=False)
    except:
        return "Error al cargar precios."

def get_system_instruction(context_data):
    return f"""
    ROL: Asistente Comercial Senior "Lucho". Experto t√©cnico y conciso.
    BASE DE DATOS: {context_data}
    
    DIRECTRICES:
    1. PRECIOS: Los valores CSV son NETOS. Calcular SIEMPRE precio final (x1.21 IVA).
    2. SEGURIDAD: Validar CANTIDAD antes de cotizar.
    3. DATOS: Solicitar Nombre y Localidad para validar env√≠o.
    4. ALCANCE: Reservar pedidos, no emitir facturas.

    REGLAS T√âCNICAS:
    - TUBOS: Conducci√≥n 6.40m / Estructural 6.00m.
    - PLANCHUELAS: Unidad barra.
    - AISLANTES: <$10k x m2 | >$10k x rollo.

    PROTOCOLOS DE VENTA:
    - CHAPAS: Filtro Techo/Lisa. Sugerir aislante Doble Alu 10mm (semicubierto). Acopio "Bolsa de Metros".
    - TEJIDOS: Kit completo. Eco -> Acindar.
    - REJA: Diagrama ASCII visual. Cotizar Macizo vs Estructural.
    - CONSTRUCCI√ìN: Hierro ADN vs Liso. Alerta 4.2mm. Upsell Alambre/Clavos.
    - NO CATALOGADO: Derivar a consulta de stock f√≠sica.

    MATRIZ COMERCIAL:
    - LOG√çSTICA: Env√≠o bonificado en zona de influencia (El Tr√©bol, San Jorge, etc.).
    - BONIFICACIONES: >$150k (7% Chapa) | >$500k (7% Gral) | >$2M (14%).
    - GRANDES CUENTAS (>10M): Presentar precio base y derivar a Gerencia (Mart√≠n Zimaro).
    - PAGOS: Promo FirstData (Mi√©/S√°b). Contado +3% extra.

    FORMATO:
    - TICKET: Bloque ```text con desglose.
    - CIERRE: Solicitar Nombre, CUIT, Tel√©fono. Generar Link WhatsApp.
    """

def main():
    configure_interface()
    
    # 1. Autenticaci√≥n (Manejo de Errores)
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
    except Exception:
        st.error("üö® Error: Falta la API KEY en los Secrets de Streamlit.")
        st.stop()

    # 2. Carga de Datos
    csv_context = get_data()

    # 3. Historial
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "model", "content": "Hola, buenas. Soy Lucho. ¬øQu√© proyecto ten√©s hoy? ¬øTechado, rejas, pintura o construcci√≥n?"}
        ]

    for msg in st.session_state.messages:
        avatar = "üë∑‚Äç‚ôÇÔ∏è" if msg["role"] == "model" else "üë§"
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # 4. Chat
    if prompt := st.chat_input("Escrib√≠ tu consulta..."):
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        try:
            # Configuraci√≥n del Modelo PRO
            model = genai.GenerativeModel(
                model_name=MODEL_ID,
                system_instruction=get_system_instruction(csv_context)
            )
            
            # Adaptaci√≥n del historial para la librer√≠a cl√°sica
            chat_history = []
            for m in st.session_state.messages:
                if m["role"] != "system":
                    role = "user" if m["role"] == "user" else "model"
                    chat_history.append({"role": role, "parts": [m["content"]]})

            chat = model.start_chat(history=chat_history)
            response = chat.send_message(prompt)
            
            with st.chat_message("model", avatar="üë∑‚Äç‚ôÇÔ∏è"):
                st.markdown(response.text)
            st.session_state.messages.append({"role": "model", "content": response.text})

        except Exception as e:
            # Diagn√≥stico claro
            error_msg = str(e)
            if "404" in error_msg:
                st.error(f"‚ö†Ô∏è Error de Modelo: Google no encuentra '{MODEL_ID}'. Intentando fallback...")
                # Fallback autom√°tico a Flash
                try:
                    fallback_model = genai.GenerativeModel(model_name="gemini-1.5-flash", system_instruction=get_system_instruction(csv_context))
                    chat = fallback_model.start_chat(history=chat_history)
                    response = chat.send_message(prompt)
                    with st.chat_message("model", avatar="üë∑‚Äç‚ôÇÔ∏è"):
                        st.markdown(response.text)
                    st.session_state.messages.append({"role": "model", "content": response.text})
                except:
                    st.error("No se pudo conectar con ning√∫n modelo.")
            elif "429" in error_msg:
                st.warning("‚è≥ Tr√°fico alto. Por favor esper√° 10 segundos y reintent√°.")
            else:
                st.error(f"‚ùå Error t√©cnico: {error_msg}")

if __name__ == "__main__":
    main()
